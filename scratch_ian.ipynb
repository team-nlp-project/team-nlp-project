{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e5f1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Optional, Union, cast\n",
    "import requests\n",
    "\n",
    "from env import github_token, github_username\n",
    "from most_forked_repos import repos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9f5dcb",
   "metadata": {},
   "source": [
    "# Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e513bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPOS = repos\n",
    "\n",
    "headers = {\"Authorization\": f\"token {github_token}\", \"User-Agent\": github_username}\n",
    "\n",
    "if headers[\"Authorization\"] == \"token \" or headers[\"User-Agent\"] == \"\":\n",
    "    raise Exception(\n",
    "        \"You need to follow the instructions marked TODO in this script before trying to use it\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b8a5940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def github_api_request(url: str) -> Union[List, Dict]:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response_data = response.json()\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            f\"Error response from github api! status code: {response.status_code}, \"\n",
    "            f\"response: {json.dumps(response_data)}\"\n",
    "        )\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90667a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_language(repo: str) -> str:\n",
    "    url = f\"https://api.github.com/repos/{repo}\"\n",
    "    repo_info = github_api_request(url)\n",
    "    if type(repo_info) is dict:\n",
    "        repo_info = cast(Dict, repo_info)\n",
    "        if \"language\" not in repo_info:\n",
    "            raise Exception(\n",
    "                \"'language' key not round in response\\n{}\".format(json.dumps(repo_info))\n",
    "            )\n",
    "        return repo_info[\"language\"]\n",
    "    raise Exception(\n",
    "        f\"Expecting a dictionary response from {url}, instead got {json.dumps(repo_info)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28080784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_contents(repo: str) -> List[Dict[str, str]]:\n",
    "    url = f\"https://api.github.com/repos/{repo}/contents/\"\n",
    "    contents = github_api_request(url)\n",
    "    if type(contents) is list:\n",
    "        contents = cast(List, contents)\n",
    "        return contents\n",
    "    raise Exception(\n",
    "        f\"Expecting a list response from {url}, instead got {json.dumps(contents)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa3143a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_readme_download_url(files: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Takes in a response from the github api that lists the files in a repo and\n",
    "    returns the url that can be used to download the repo's README file.\n",
    "    \"\"\"\n",
    "    for file in files:\n",
    "        if file[\"name\"].lower().startswith(\"readme\"):\n",
    "            return file[\"download_url\"]\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ccfbe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_repo(repo: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Takes a repo name like \"gocodeup/codeup-setup-script\" and returns a\n",
    "    dictionary with the language of the repo and the readme contents.\n",
    "    \"\"\"\n",
    "    contents = get_repo_contents(repo)\n",
    "    readme_download_url = get_readme_download_url(contents)\n",
    "    if readme_download_url == \"\":\n",
    "        readme_contents = \"\"\n",
    "    else:\n",
    "        readme_contents = requests.get(readme_download_url).text\n",
    "    print(repo)\n",
    "    return {\n",
    "        \"repo\": repo,\n",
    "        \"language\": get_repo_language(repo),\n",
    "        \"readme_contents\": readme_contents,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5ee8644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_github_data() -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Loop through all of the repos and process them. Returns the processed data.\n",
    "    \"\"\"\n",
    "    return [process_repo(repo) for repo in REPOS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fd9137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jtleek/datasharing\n",
      "rdpeng/ProgrammingAssignment2\n",
      "octocat/Spoon-Knife\n",
      "tensorflow/tensorflow\n",
      "SmartThingsCommunity/SmartThingsPublic\n",
      "twbs/bootstrap\n",
      "github/gitignore\n",
      "Pierian-Data/Complete-Python-3-Bootcamp\n",
      "nightscout/cgm-remote-monitor\n",
      "rdpeng/ExData_Plotting1\n",
      "jwasham/coding-interview-university\n",
      "opencv/opencv\n",
      "EbookFoundation/free-programming-books\n",
      "CyC2018/CS-Notes\n",
      "tensorflow/models\n",
      "eugenp/tutorials\n",
      "jackfrued/Python-100-Days\n",
      "firstcontributions/first-contributions\n",
      "torvalds/linux\n",
      "Snailclimb/JavaGuide\n",
      "rdpeng/RepData_PeerAssessment1\n",
      "facebook/react\n",
      "spring-projects/spring-boot\n",
      "jlord/patchwork\n",
      "TheAlgorithms/Python\n",
      "barryclark/jekyll-now\n",
      "spring-projects/spring-framework\n",
      "DataScienceSpecialization/courses\n",
      "ant-design/ant-design\n",
      "vuejs/vue\n",
      "github/docs\n",
      "getify/You-Dont-Know-JS\n",
      "angular/angular.js\n",
      "donnemartin/system-design-primer\n",
      "freeCodeCamp/freeCodeCamp\n",
      "DefinitelyTyped/DefinitelyTyped\n",
      "PanJiaChen/vue-element-admin\n",
      "django/django\n",
      "kamranahmedse/developer-roadmap\n",
      "apache/spark\n",
      "django/django\n",
      "kamranahmedse/developer-roadmap\n",
      "apache/spark\n",
      "mui-org/material-ui\n",
      "apache/dubbo\n",
      "justjavac/free-programming-books-zh_CN\n",
      "facebook/create-react-app\n",
      "ohmyzsh/ohmyzsh\n",
      "dotnet/AspNetCore.Docs\n",
      "udacity/frontend-nanodegree-resume\n",
      "macrozheng/mall\n",
      "d3/d3\n",
      "git/git\n",
      "qmk/qmk_firmware\n",
      "scikit-learn/scikit-learn\n",
      "iluwatar/java-design-patterns\n",
      "airbnb/javascript\n",
      "sindresorhus/awesome\n",
      "laravel/laravel\n",
      "nodejs/node\n",
      "996icu/996.ICU\n",
      "facebook/react-native\n",
      "ansible/ansible\n",
      "LarryMad/recipes\n",
      "RedHatTraining/DO180-apps\n",
      "slatedocs/slate\n",
      "google/it-cert-automation-practice\n",
      "elastic/elasticsearch\n",
      "python/cpython\n",
      "microsoft/vscode\n",
      "trekhleb/javascript-algorithms\n",
      "angular/angular\n",
      "redis/redis\n",
      "jquery/jquery\n",
      "wesbos/JavaScript30\n",
      "vinta/awesome-python\n",
      "rails/rails\n",
      "shadowsocks/shadowsocks\n",
      "flutter/flutter\n",
      "labuladong/fucking-algorithm\n",
      "public-apis/public-apis\n",
      "BVLC/caffe\n",
      "keras-team/keras\n",
      "pjreddie/darknet\n",
      "apache/echarts\n",
      "danielmiessler/SecLists\n",
      "moby/moby\n",
      "CSSEGISandData/COVID-19\n",
      "MicrosoftDocs/mslearn-tailspin-spacegame-web\n",
      "ColorlibHQ/AdminLTE\n",
      "helm/charts\n",
      "mmistakes/minimal-mistakes\n",
      "xingshaocheng/architect-awesome\n",
      "wakaleo/game-of-life\n",
      "jenkins-docs/simple-java-maven-app\n",
      "atom/atom\n",
      "academicpages/academicpages.github.io\n",
      "scm-ninja/starter-web\n",
      "shadowsocks/shadowsocks-windows\n",
      "doocs/advanced-java\n",
      "hakimel/reveal.js\n",
      "udacity/course-collaboration-travel-plans\n",
      "home-assistant/core\n",
      "coolsnowwolf/lede\n",
      "MarlinFirmware/Marlin\n",
      "aymericdamien/TensorFlow-Examples\n",
      "vercel/next.js\n",
      "reduxjs/redux\n",
      "coding-boot-camp/prework-about-me\n",
      "pallets/flask\n",
      "aymericdamien/TensorFlow-Examples\n",
      "vercel/next.js\n",
      "reduxjs/redux\n",
      "coding-boot-camp/prework-about-me\n",
      "pallets/flask\n",
      "atralice/Curso.Prep.Henry\n",
      "MicrosoftDocs/azure-docs\n",
      "scutan90/DeepLearning-500-questions\n",
      "pytorch/pytorch\n",
      "jakevdp/PythonDataScienceHandbook\n",
      "spring-projects/spring-petclinic\n",
      "tastejs/todomvc\n",
      "TheAlgorithms/Java\n",
      "selfteaching/the-craft-of-selfteaching\n",
      "netty/netty\n",
      "lewagon/dotfiles\n",
      "Azure/azure-quickstart-templates\n",
      "ossu/computer-science\n",
      "golang/go\n",
      "ionic-team/ionic-framework\n",
      "pandas-dev/pandas\n",
      "protocolbuffers/protobuf\n",
      "ElemeFE/element\n",
      "MisterBooo/LeetCodeAnimation\n",
      "electron/electron\n",
      "josephmisiti/awesome-machine-learning\n",
      "233boy/v2ray\n",
      "huggingface/transformers\n",
      "ageron/handson-ml\n",
      "wesm/pydata-book\n",
      "leereilly/swot\n",
      "ethereum/go-ethereum\n",
      "github/opensource.guide\n",
      "Trinea/android-open-project\n",
      "bailicangdu/vue2-elm\n",
      "udacity/fullstack-nanodegree-vm\n",
      "Homebrew/legacy-homebrew\n",
      "h5bp/html5-boilerplate\n",
      "angular/angular-cli\n",
      "ageitgey/face_recognition\n",
      "daattali/beautiful-jekyll\n",
      "ArduPilot/ardupilot\n",
      "rapid7/metasploit-framework\n",
      "FortAwesome/Font-Awesome\n",
      "linuxacademy/devops-essentials-sample-app\n",
      "esp8266/Arduino\n",
      "ityouknow/spring-boot-examples\n",
      "kdn251/interviews\n",
      "shadowsocks/shadowsocks-android\n",
      "getlantern/lantern\n",
      "google/styleguide\n",
      "PX4/PX4-Autopilot\n",
      "deepfakes/faceswap\n",
      "chartjs/Chart.js\n",
      "mybatis/mybatis-3\n",
      "danistefanovic/build-your-own-x\n",
      "zero-to-mastery/start-here-guidelines\n",
      "springframeworkguru/spring5webapp\n",
      "android/architecture-samples\n",
      "FreeRDP/FreeRDP\n",
      "googlehosts/hosts\n",
      "apache/kafka\n",
      "jlevy/the-art-of-command-line\n",
      "heroku/node-js-sample\n",
      "apachecn/AiLearning\n",
      "AllenDowney/ThinkStats2\n",
      "geekcomputers/Python\n",
      "WordPress/WordPress\n",
      "necolas/normalize.css\n",
      "othneildrew/Best-README-Template\n",
      "astaxie/build-web-application-with-golang\n",
      "AFNetworking/AFNetworking\n",
      "adam-p/markdown-here\n",
      "matterport/Mask_RCNN\n",
      "codebasics/py\n",
      "learn-co-students/python-practice-with-datatypes-data-science-intro-000\n",
      "karan/Projects\n",
      "wasabeef/awesome-android-ui\n",
      "kubernetes/website\n",
      "h5bp/Front-end-Developer-Interview-Questions\n",
      "Blankj/AndroidUtilCode\n",
      "fighting41love/funNLP\n",
      "gatsbyjs/gatsby\n",
      "jeecgboot/jeecg-boot\n",
      "fivethirtyeight/data\n",
      "kallaway/100-days-of-code\n",
      "socketio/socket.io\n",
      "microsoft/TypeScript\n",
      "Homebrew/homebrew-core\n",
      "apache/flink\n",
      "udacity/create-your-own-adventure\n",
      "woocommerce/woocommerce\n",
      "bettiolo/node-echo\n",
      "jekyll/jekyll\n",
      "nolimits4web/swiper\n",
      "apache/airflow\n",
      "spmallick/learnopencv\n",
      "google/guava\n",
      "jonasschmedtmann/complete-javascript-course\n",
      "github/explore\n",
      "testerSunshine/12306\n",
      "apolloconfig/apollo\n",
      "Homebrew/homebrew-cask\n",
      "scrapy/scrapy\n",
      "lenve/vhr\n",
      "jhu-ep-coursera/fullstack-course4\n",
      "30-seconds/30-seconds-of-code\n",
      "expressjs/express\n",
      "apple/swift\n",
      "vuejs/vuex\n",
      "fatedier/frp\n",
      "learn-co-students/python-variables-readme-data-science-intro-000\n",
      "avelino/awesome-go\n",
      "zxing/zxing\n",
      "youzan/vant\n",
      "PHPMailer/PHPMailer\n",
      "kelseyhightower/kubernetes-the-hard-way\n",
      "trustwallet/assets\n",
      "CocoaPods/Specs\n",
      "fengdu78/Coursera-ML-AndrewNg-Notes\n",
      "remix-run/react-router\n",
      "ageron/handson-ml2\n",
      "ruanyf/es6tutorial\n",
      "georgearun/Data-Science--Cheat-Sheet\n",
      "PhilJay/MPAndroidChart\n",
      "psf/requests\n",
      "grpc/grpc\n",
      "mozilla/pdf.js\n",
      "azl397985856/leetcode\n",
      "yangshun/tech-interview-handbook\n",
      "vuejs/awesome-vue\n",
      "jleetutorial/maven-project\n",
      "chanjarster/weixin-java-tools\n",
      "mathiasbynens/dotfiles\n",
      "square/okhttp\n",
      "magento/magento2\n",
      "swisskyrepo/PayloadsAllTheThings\n",
      "laravel/framework\n",
      "soimort/you-get\n",
      "remix-run/react-router\n",
      "ageron/handson-ml2\n",
      "ruanyf/es6tutorial\n",
      "georgearun/Data-Science--Cheat-Sheet\n",
      "PhilJay/MPAndroidChart\n",
      "psf/requests\n",
      "grpc/grpc\n",
      "mozilla/pdf.js\n",
      "azl397985856/leetcode\n",
      "yangshun/tech-interview-handbook\n",
      "TryGhost/Ghost\n",
      "microsoft/Windows-universal-samples\n",
      "puppeteer/puppeteer\n",
      "kelthuzadx/hosts\n",
      "ruicky/jd_sign_bot\n",
      "godotengine/godot\n",
      "XX-net/XX-Net\n",
      "ApolloAuto/apollo\n",
      "bcit-ci/CodeIgniter\n",
      "typicode/demo\n",
      "hasura/imad-app\n",
      "alibaba/druid\n",
      "RedHatTraining/DO288-apps\n",
      "shadowsocks/ShadowsocksX-NG\n",
      "udacity/ud839_Miwok\n",
      "OAI/OpenAPI-Specification\n",
      "microsoft/Windows-universal-samples\n",
      "puppeteer/puppeteer\n",
      "kelthuzadx/hosts\n",
      "ruicky/jd_sign_bot\n",
      "godotengine/godot\n",
      "learn-co-students/jupyter-notebook-introduction-data-science-intro-000\n",
      "checkstyle/checkstyle\n",
      "education/GitHubGraduation-2021\n",
      "pytorch/examples\n",
      "flutter/plugins\n",
      "google/googletest\n",
      "alibaba/druid\n",
      "RedHatTraining/DO288-apps\n",
      "shadowsocks/ShadowsocksX-NG\n",
      "udacity/ud839_Miwok\n",
      "OAI/OpenAPI-Specification\n",
      "microsoft/Windows-universal-samples\n",
      "puppeteer/puppeteer\n",
      "kelthuzadx/hosts\n",
      "ruicky/jd_sign_bot\n",
      "godotengine/godot\n",
      "XX-net/XX-Net\n",
      "ApolloAuto/apollo\n",
      "bcit-ci/CodeIgniter\n",
      "typicode/demo\n",
      "hasura/imad-app\n",
      "yankils/Simple-DevOps-Project\n",
      "forezp/SpringCloudLearning\n",
      "freddier/hyperblog\n",
      "bilibili/ijkplayer\n",
      "justjavac/awesome-wechat-weapp\n",
      "android/architecture-components-samples\n",
      "tesseract-ocr/tesseract\n",
      "nodejs/node-v0.x-archive\n",
      "learn-co-students/python-lists-readme-data-science-intro-000\n",
      "bradtraversy/design-resources-for-developers\n",
      "ryanmcdermott/clean-code-javascript\n",
      "unknwon/the-way-to-go_ZH_CN\n",
      "ReactiveX/RxJava\n",
      "lib-pku/libpku\n",
      "apache/hadoop\n",
      "hyperledger/fabric\n",
      "shuzheng/zheng\n",
      "CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers\n",
      "Hack-with-Github/Awesome-Hacking\n",
      "prakhar1989/awesome-courses\n",
      "sahat/hackathon-starter\n",
      "discourse/discourse\n",
      "yankils/hello-world\n",
      "alvarotrigo/fullPage.js\n",
      "akveo/ngx-admin\n",
      "openssl/openssl\n",
      "andyzys/jd_seckill\n",
      "qiubaiying/qiubaiying.github.io\n",
      "anuraghazra/github-readme-stats\n",
      "QSCTech/zju-icicles\n",
      "elastic/kibana\n",
      "Alamofire/Alamofire\n",
      "halo-dev/halo\n",
      "php/php-src\n",
      "impress/impress.js\n",
      "NixOS/nixpkgs\n",
      "fchollet/deep-learning-with-python-notebooks\n",
      "yunjey/pytorch-tutorial\n",
      "amjuarez/bytecoin\n",
      "crossoverJie/JCSprout\n",
      "fastai/fastai\n",
      "udacity/ud851-Exercises\n",
      "ant-design/ant-design-pro\n",
      "learn-co-students/python-lists-lab-data-science-intro-000\n",
      "learn-co-students/js-from-dom-to-node-bootcamp-prep-000\n",
      "chinese-poetry/chinese-poetry\n",
      "guodongxiaren/README\n",
      "swirldev/swirl_courses\n",
      "jenkinsci/jenkins\n",
      "desktop/desktop\n",
      "jrowberg/i2cdevlib\n",
      "learn-co-students/javascript-intro-to-functions-lab-bootcamp-prep-000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angular-ui/bootstrap\n",
      "dotnet/aspnetcore\n",
      "RocketChat/Rocket.Chat\n",
      "hashicorp/terraform\n",
      "macrozheng/mall-learning\n",
      "moment/moment\n",
      "square/retrofit\n",
      "yiisoft/yii2\n",
      "cocos2d/cocos2d-x\n",
      "521xueweihan/HelloGitHub\n",
      "microsoft/terminal\n",
      "videojs/video.js\n",
      "seata/seata\n",
      "arduino/Arduino\n",
      "JeffLi1993/springboot-learning-example\n",
      "romeokienzler/TensorFlow\n",
      "QSCTech/zju-icicles\n",
      "elastic/kibana\n",
      "Alamofire/Alamofire\n",
      "apache/incubator-mxnet\n",
      "halo-dev/halo\n",
      "php/php-src\n",
      "impress/impress.js\n",
      "NixOS/nixpkgs\n",
      "fchollet/deep-learning-with-python-notebooks\n",
      "yunjey/pytorch-tutorial\n",
      "amjuarez/bytecoin\n",
      "microsoft/sql-server-samples\n",
      "sentsin/layui\n",
      "xamarin/xamarin-forms-samples\n",
      "Micropoor/Micro8\n",
      "ColorlibHQ/gentelella\n",
      "donnemartin/data-science-ipython-notebooks\n",
      "Homebrew/brew\n",
      "dcloudio/mui\n",
      "amix/vimrc\n",
      "vnpy/vnpy\n",
      "chrislgarry/Apollo-11\n",
      "CMU-Perceptual-Computing-Lab/openpose\n",
      "phonegap/phonegap-start\n",
      "learn-co-students/py-lists-with-maps-data-science-intro-000\n",
      "storybookjs/storybook\n",
      "iperov/DeepFaceLab\n",
      "floodsung/Deep-Learning-Papers-Reading-Roadmap\n",
      "OpenZeppelin/openzeppelin-contracts\n",
      "SeleniumHQ/selenium\n",
      "github/personal-website\n",
      "wuyouzhuguli/SpringAll\n",
      "photonstorm/phaser\n",
      "Alvin9999/new-pac\n",
      "Activiti/Activiti\n",
      "linlinjava/litemall\n",
      "NARKOZ/hacker-scripts\n",
      "akullpp/awesome-java\n",
      "prometheus/prometheus\n",
      "Tencent/weui\n",
      "codepath/android_guides\n",
      "learn-co-students/js-if-else-files-lab-bootcamp-prep-000\n",
      "apache/zookeeper\n",
      "alibaba/spring-cloud-alibaba\n",
      "nostra13/Android-Universal-Image-Loader\n",
      "select2/select2\n",
      "alibaba/canal\n",
      "gohugoio/hugo\n",
      "DrKLO/Telegram\n",
      "ytdl-org/youtube-dl\n",
      "libgdx/libgdx\n",
      "clowwindy/shadowsocks-libev\n",
      "rafaballerini/rafaballerini\n",
      "wangzheng0822/algo\n",
      "thebigsmileXD/PocketMine-0.13.0\n",
      "learn-co-students/js-functions-lab-bootcamp-prep-000\n",
      "alibaba/fastjson\n",
      "udacity/machine-learning\n",
      "learn-co-students/first-ide-lab-bootcamp-prep-000\n",
      "learn-co-students/js-if-else-files-lab-bootcamp-prep-000\n",
      "apache/zookeeper\n",
      "alibaba/spring-cloud-alibaba\n",
      "nostra13/Android-Universal-Image-Loader\n",
      "select2/select2\n",
      "alibaba/canal\n",
      "gohugoio/hugo\n",
      "DrKLO/Telegram\n",
      "ytdl-org/youtube-dl\n",
      "libgdx/libgdx\n",
      "ServiceNow/devtraining-needit-orlando\n",
      "alibaba/Sentinel\n",
      "ultralytics/yolov5\n",
      "composer/composer\n",
      "google/iosched\n",
      "uxsolutions/bootstrap-datepicker\n",
      "matplotlib/matplotlib\n",
      "deadlyvipers/dojo_rules\n",
      "Binaryify/NeteaseCloudMusicApi\n",
      "elunez/eladmin\n",
      "numpy/numpy\n",
      "lodash/lodash\n",
      "faif/python-patterns\n",
      "dromara/hutool\n",
      "open-mmlab/mmdetection\n",
      "alibaba/arthas\n",
      "aosp-mirror/platform_frameworks_base\n",
      "google/leveldb\n",
      "hussien89aa/AndroidTutorialForBeginners\n",
      "ZuzooVn/machine-learning-for-software-engineers\n",
      "nothings/stb\n",
      "zhiwehu/Python-programming-exercises\n",
      "gin-gonic/gin\n",
      "vuetifyjs/vuetify\n",
      "react-boilerplate/react-boilerplate\n",
      "encode/django-rest-framework\n",
      "huihut/interview\n",
      "angular/components\n",
      "mbadolato/iTerm2-Color-Schemes\n",
      "aosabook/500lines\n",
      "helm/helm\n",
      "mnielsen/neural-networks-and-deep-learning\n",
      "PanJiaChen/vue-admin-template\n",
      "datasciencemasters/go\n",
      "Genymobile/scrcpy\n",
      "learn-co-students/js-what-is-a-test-lab-bootcamp-prep-000\n",
      "guipsamora/pandas_exercises\n",
      "thinkgem/jeesite\n",
      "vuejs/vue-cli\n",
      "qiurunze123/miaosha\n",
      "mqvida/PowerBI-DataScience\n",
      "hashicorp/terraform-provider-aws\n",
      "ansible/ansible-examples\n",
      "bumptech/glide\n",
      "ariya/phantomjs\n",
      "algorithm-visualizer/algorithm-visualizer\n",
      "fffaraz/awesome-cpp\n",
      "istio/istio\n",
      "CodingTrain/website\n",
      "ServiceNow/devtraining-needit-paris\n",
      "xbmc/xbmc\n",
      "kenwheeler/slick\n",
      "leonardomso/33-js-concepts\n",
      "SDWebImage/SDWebImage\n",
      "linuxacademy/cicd-pipeline-train-schedule-git\n",
      "sdmg15/Best-websites-a-programmer-should-visit\n",
      "actionsdemos/calculator\n",
      "alibaba/easyexcel\n",
      "modood/Administrative-divisions-of-China\n",
      "jenkins-docs/simple-node-js-react-npm-app\n",
      "kubernetes/ingress-nginx\n",
      "yankouskia/additional_5\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = scrape_github_data()\n",
    "    json.dump(data, open(\"data.json\", \"w\"), indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab23c7d",
   "metadata": {},
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac6901eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8be02fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(some_string):\n",
    "    '''\n",
    "    Takes in a string and makes all characters lowercased, normalizes unicode characters, and removes any character that is not a letter, number, ', or space\n",
    "    '''\n",
    "    some_string = some_string.lower()\n",
    "    some_string = unicodedata.normalize('NFKD', some_string).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    some_string = re.sub(r\"[^a-z0-9'\\s]\", '', some_string)\n",
    "    return some_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "081b40e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(some_string):\n",
    "    '''\n",
    "    Takes in a string and tokenizes it\n",
    "    '''\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    some_string = tokenizer.tokenize(some_string, return_str = True)\n",
    "    return some_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c8a7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(some_string, extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    Takes in a string and removes stopwords in nltk stopwords list, user can also pass list of words to add or remove from default list of stopwords\n",
    "    '''\n",
    "    stopword_list = stopwords.words('english')\n",
    "    [stopword_list.append(word) for word in extra_words]\n",
    "    [stopword_list.remove(word) for word in extra_words]\n",
    "    words = some_string.split()\n",
    "    filtered_words = [word for word in words if word not in stopword_list]\n",
    "    some_string_without_stopwords = ' '.join(filtered_words)\n",
    "    return some_string_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "336ea9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(some_string):\n",
    "    '''\n",
    "    Takes in a string and returns a string with all words lemmatized\n",
    "    '''\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in some_string.split()]\n",
    "    some_string_lemmatized = ' '.join(lemmas)\n",
    "    return some_string_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4e78b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(some_string):\n",
    "    '''\n",
    "    Takes in a string and returns a string with all words stemmed\n",
    "    '''\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in some_string.split()]\n",
    "    some_string_stemmed = ' '.join(stems)\n",
    "    return some_string_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c7c8d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_nlp(df, original_text_col = 'original', extra_words = [], exclude_words = []):\n",
    "    '''\n",
    "    Take in df with raw content, create new columns for cleaned content, stemmed content, and lemmatized content\n",
    "    '''\n",
    "    df['clean'] = df[original_text_col].apply(basic_clean).apply(tokenize).apply(remove_stopwords, extra_words, exclude_words)\n",
    "    df['stemmed'] = df.clean.apply(stem)\n",
    "    df['lemmatized'] = df.clean.apply(lemmatize)\n",
    "    df = df.dropna()\n",
    "    top4 = ['JavaScript', 'Java', 'Python', 'C++']\n",
    "    df.language = df.language.apply(lambda x: 'Other' if x not in top4 else x)\n",
    "    df = df[df.language != 'Other']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7436c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_readme(df):\n",
    "    '''\n",
    "    This function takes in a df and splits it into train, validate, and test dfs\n",
    "    final proportions will be 60/20/20 for train/validate/test\n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=.2, random_state=123, stratify=df.language)\n",
    "    train, validate = train_test_split(train_validate, test_size=.25, random_state=123, stratify=train_validate.language)\n",
    "    train_prop = train.shape[0] / df.shape[0]\n",
    "    val_prop = validate.shape[0] / df.shape[0]\n",
    "    test_prop = test.shape[0]/df.shape[0]\n",
    "    print(f'Train Proportion: {train_prop:.2f} ({train.shape[0]} rows)\\nValidate Proportion: {val_prop:.2f} ({validate.shape[0]} rows)\\\n",
    "    \\nTest Proportion: {test_prop:.2f} ({test.shape[0]} rows)')\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297cacfb",
   "metadata": {},
   "source": [
    "# Practice Acquire and Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35bb1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import strftime\n",
    "import numpy as np\n",
    "\n",
    "import scrape_url_list as s\n",
    "import acquire as a\n",
    "import prepare as p\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "758fae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/josephmisiti/awesome-machine-learning',\n",
       " 'https://github.com/microsoft/ML-For-Beginners',\n",
       " 'https://github.com/bfortuner/ml-glossary',\n",
       " 'https://github.com/trekhleb/homemade-machine-learning',\n",
       " 'https://github.com/dangkhoasdc/awesome-ai-residency',\n",
       " 'https://github.com/Spandan-Madan/DeepLearningProject',\n",
       " 'https://github.com/roboticcam/machine-learning-notes',\n",
       " 'https://github.com/ZuzooVn/machine-learning-for-software-engineers',\n",
       " 'https://github.com/eugeneyan/applied-ml',\n",
       " 'https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap',\n",
       " 'https://github.com/khangich/machine-learning-interview',\n",
       " 'https://github.com/EthicalML/awesome-production-machine-learning',\n",
       " 'https://github.com/Machine-Learning-Tokyo/Interactive_Tools',\n",
       " 'https://github.com/GokuMohandas/MadeWithML',\n",
       " 'https://github.com/ml-tooling/best-of-ml-python',\n",
       " 'https://github.com/yandexdataschool/Practical_RL',\n",
       " 'https://github.com/visenger/awesome-mlops',\n",
       " 'https://github.com/aladdinpersson/Machine-Learning-Collection',\n",
       " 'https://github.com/sshkhr/awesome-mlss',\n",
       " 'https://github.com/ybayle/awesome-deep-learning-music',\n",
       " 'https://github.com/eugeneyan/ml-surveys',\n",
       " 'https://github.com/extreme-assistant/CVPR2021-Paper-Code-Interpretation',\n",
       " 'https://github.com/ahkarami/Deep-Learning-in-Production',\n",
       " 'https://github.com/labmlai/annotated_deep_learning_paper_implementations',\n",
       " 'https://github.com/awesomedata/awesome-public-datasets',\n",
       " 'https://github.com/jtoy/awesome-tensorflow',\n",
       " 'https://github.com/kmario23/deep-learning-drizzle',\n",
       " 'https://github.com/src-d/awesome-machine-learning-on-source-code',\n",
       " 'https://github.com/manfreddiaz/awesome-autonomous-vehicles',\n",
       " 'https://github.com/nashory/gans-awesome-applications',\n",
       " 'https://github.com/jbhuang0604/awesome-computer-vision',\n",
       " 'https://github.com/ritchieng/the-incredible-pytorch',\n",
       " 'https://github.com/keon/awesome-nlp',\n",
       " 'https://github.com/humphd/have-fun-with-machine-learning',\n",
       " 'https://github.com/alirezadir/Production-Level-Deep-Learning',\n",
       " 'https://github.com/aikorea/awesome-rl/',\n",
       " 'https://github.com/afshinea/stanford-cs-229-machine-learning',\n",
       " 'https://github.com/terryum/awesome-deep-learning-papers',\n",
       " 'https://github.com/zotroneneis/machine_learning_basics',\n",
       " 'https://github.com/dustinvtran/ml-videos',\n",
       " 'https://github.com/JoseDeFreitas/awesome-youtubers#machine-learning',\n",
       " 'https://github.com/ujjwalkarn/Machine-Learning-Tutorials',\n",
       " 'https://github.com/ChristosChristofidis/awesome-deep-learning',\n",
       " 'https://github.com/edobashira/speech-language-processing',\n",
       " 'https://github.com/susanli2016/Machine-Learning-with-Python',\n",
       " 'https://github.com/timzhang642/3D-Machine-Learning',\n",
       " 'https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials',\n",
       " 'https://github.com/firmai/industry-machine-learning',\n",
       " 'https://github.com/dformoso/machine-learning-mindmap',\n",
       " 'https://github.com/tirthajyoti/Machine-Learning-with-Python',\n",
       " 'https://github.com/firmai/financial-machine-learning',\n",
       " 'https://github.com/jphall663/awesome-machine-learning-interpretability',\n",
       " 'https://github.com/krasserm/bayesian-machine-learning',\n",
       " 'https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems',\n",
       " 'https://github.com/wtsxDev/Machine-Learning-for-Cyber-Security',\n",
       " 'https://github.com/owainlewis/awesome-artificial-intelligence',\n",
       " 'https://github.com/louisfb01/start-machine-learning',\n",
       " 'https://github.com/ashishpatel26/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code',\n",
       " 'https://github.com/fritzlabs/Awesome-Mobile-Machine-Learning',\n",
       " 'https://github.com/metrofun/machine-learning-surveys',\n",
       " 'https://github.com/eriklindernoren/ML-From-Scratch',\n",
       " 'https://github.com/HuaizhengZhang/Awesome-System-for-Machine-Learning',\n",
       " 'https://github.com/grananqvist/Awesome-Quant-Machine-Learning-Trading',\n",
       " 'https://github.com/jivoi/awesome-ml-for-cybersecurity',\n",
       " 'https://github.com/rushter/MLAlgorithms',\n",
       " 'https://github.com/huseinzol05/Stock-Prediction-Models',\n",
       " 'https://github.com/lukas/ml-class',\n",
       " 'https://github.com/huseinzol05/NLP-Models-Tensorflow',\n",
       " 'https://github.com/kjw0612/awesome-deep-vision',\n",
       " 'https://github.com/NirantK/awesome-project-ideas',\n",
       " 'https://github.com/pliang279/awesome-multimodal-ml',\n",
       " 'https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd',\n",
       " 'https://github.com/arbox/machine-learning-with-ruby',\n",
       " 'https://github.com/naganandy/graph-based-deep-learning-literature',\n",
       " 'https://github.com/weiaicunzai/awesome-image-classification',\n",
       " 'https://github.com/sbrugman/deep-learning-papers',\n",
       " 'https://github.com/abhineet123/Deep-Learning-for-Tracking-and-Detection',\n",
       " 'https://github.com/DeepGraphLearning/LiteratureDL4Graph',\n",
       " 'https://github.com/vinta/awesome-python',\n",
       " 'https://github.com/spmallick/learnopencv',\n",
       " 'https://github.com/AMAI-GmbH/AI-Expert-Roadmap',\n",
       " 'https://github.com/heartexlabs/awesome-data-labeling',\n",
       " 'https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow',\n",
       " 'https://github.com/omarsar/nlp_overview',\n",
       " 'https://github.com/mathsyouth/awesome-text-summarization',\n",
       " 'https://github.com/benedekrozemberczki/awesome-community-detection',\n",
       " 'https://github.com/D-X-Y/Awesome-AutoDL',\n",
       " 'https://github.com/shaoxiongji/knowledge-graphs',\n",
       " 'https://github.com/NiuTrans/ABigSurvey',\n",
       " 'https://github.com/fuzhenxin/Style-Transfer-in-Text',\n",
       " 'https://github.com/bharathgs/Awesome-pytorch-list',\n",
       " 'https://github.com/thunlp/TAADpapers',\n",
       " 'https://github.com/Kyubyong/nlp_tasks',\n",
       " 'https://github.com/Developer-Y/cs-video-courses#artificial-intelligence',\n",
       " 'https://github.com/openMVG/awesome_3DReconstruction_list',\n",
       " 'https://github.com/xinghaochen/awesome-hand-pose-estimation',\n",
       " 'https://github.com/balavenkatesh3322/CV-pretrained-model',\n",
       " 'https://github.com/hwalsuklee/awesome-deep-text-detection-recognition',\n",
       " 'https://github.com/lzhbrian/image-to-image-papers',\n",
       " 'https://github.com/sekwiatkowski/awesome-capsule-networks',\n",
       " 'https://github.com/unrealcv/synthetic-computer-vision',\n",
       " 'https://github.com/weihaox/awesome-neural-rendering',\n",
       " 'https://github.com/dragen1860/TensorFlow-2.x-Tutorials',\n",
       " 'https://github.com/AgaMiko/data-augmentation-review',\n",
       " 'https://github.com/MaxBenChrist/awesome_time_series_in_python',\n",
       " 'https://github.com/hoya012/awesome-anomaly-detection',\n",
       " 'https://github.com/hibayesian/awesome-automl-papers',\n",
       " 'https://github.com/cbailes/awesome-deep-trading',\n",
       " 'https://github.com/jinwchoi/awesome-action-recognition',\n",
       " 'https://github.com/amusi/awesome-object-detection',\n",
       " 'https://github.com/rasbt/pattern_classification',\n",
       " 'https://github.com/robmarkcole/satellite-image-deep-learning',\n",
       " 'https://github.com/vahidk/EffectiveTensorflow',\n",
       " 'https://github.com/Hvass-Labs/TensorFlow-Tutorials',\n",
       " 'https://github.com/zhangqianhui/AdversarialNetsPapers',\n",
       " 'https://github.com/dair-ai/nlp_paper_summaries',\n",
       " 'https://github.com/mbadry1/DeepLearning.ai-Summary',\n",
       " 'https://github.com/instillai/deep-learning-roadmap',\n",
       " 'https://github.com/onnx/models',\n",
       " 'https://github.com/jason718/awesome-self-supervised-learning',\n",
       " 'https://github.com/microsoft/nlp-recipes',\n",
       " 'https://github.com/poloclub/cnn-explainer',\n",
       " 'https://github.com/ChanChiChoi/awesome-Face_Recognition',\n",
       " 'https://github.com/aymericdamien/TopDeepLearning',\n",
       " 'https://github.com/hongleizhang/RSPapers',\n",
       " 'https://github.com/foolwood/benchmark_results',\n",
       " 'https://github.com/wzhe06/Ad-papers',\n",
       " 'https://github.com/andri27-ts/Reinforcement-Learning',\n",
       " 'https://github.com/aleju/papers',\n",
       " 'https://github.com/abhineet123/Deep-Learning-for-Tracking-and-Detection',\n",
       " 'https://github.com/GauravBh1010tt/DeepLearn',\n",
       " 'https://github.com/ageron/handson-ml',\n",
       " 'https://github.com/Avik-Jain/100-Days-Of-ML-Code',\n",
       " 'https://github.com/donnemartin/awesome-aws',\n",
       " 'https://github.com/endymecy/awesome-deeplearning-resources',\n",
       " 'https://github.com/likedan/Awesome-CoreML-Models',\n",
       " 'https://github.com/Vedenin/useful-java-links#ii-databases-search-engines-big-data-and-machine-learning',\n",
       " 'https://github.com/hindupuravinash/the-gan-zoo',\n",
       " 'https://github.com/benedekrozemberczki/awesome-decision-tree-papers',\n",
       " 'https://github.com/rwightman/pytorch-image-models',\n",
       " 'https://github.com/jslee02/awesome-robotics-libraries',\n",
       " 'https://github.com/firmai/machine-learning-asset-management',\n",
       " 'https://github.com/ahmedbahaaeldin/From-0-to-Research-Scientist-resources-guide',\n",
       " 'https://github.com/alirezadir/machine-learning-interview-enlightener/blob/main/README.md',\n",
       " 'https://github.com/DeepGraphLearning/LiteratureDL4Graph',\n",
       " 'https://github.com/ethen8181/machine-learning',\n",
       " 'https://github.com/ethen8181/machine-learning',\n",
       " 'https://github.com/ethen8181/machine-learning']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = s.get_cached_links()\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d29087af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/josephmisiti/awesome-machine-learning',\n",
       " 'https://github.com/microsoft/ML-For-Beginners',\n",
       " 'https://github.com/bfortuner/ml-glossary',\n",
       " 'https://github.com/trekhleb/homemade-machine-learning',\n",
       " 'https://github.com/dangkhoasdc/awesome-ai-residency',\n",
       " 'https://github.com/Spandan-Madan/DeepLearningProject',\n",
       " 'https://github.com/roboticcam/machine-learning-notes',\n",
       " 'https://github.com/ZuzooVn/machine-learning-for-software-engineers',\n",
       " 'https://github.com/eugeneyan/applied-ml',\n",
       " 'https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap',\n",
       " 'https://github.com/khangich/machine-learning-interview',\n",
       " 'https://github.com/EthicalML/awesome-production-machine-learning',\n",
       " 'https://github.com/Machine-Learning-Tokyo/Interactive_Tools',\n",
       " 'https://github.com/GokuMohandas/MadeWithML',\n",
       " 'https://github.com/ml-tooling/best-of-ml-python',\n",
       " 'https://github.com/yandexdataschool/Practical_RL',\n",
       " 'https://github.com/visenger/awesome-mlops',\n",
       " 'https://github.com/aladdinpersson/Machine-Learning-Collection',\n",
       " 'https://github.com/sshkhr/awesome-mlss',\n",
       " 'https://github.com/ybayle/awesome-deep-learning-music',\n",
       " 'https://github.com/eugeneyan/ml-surveys',\n",
       " 'https://github.com/extreme-assistant/CVPR2021-Paper-Code-Interpretation',\n",
       " 'https://github.com/ahkarami/Deep-Learning-in-Production',\n",
       " 'https://github.com/labmlai/annotated_deep_learning_paper_implementations',\n",
       " 'https://github.com/awesomedata/awesome-public-datasets',\n",
       " 'https://github.com/jtoy/awesome-tensorflow',\n",
       " 'https://github.com/kmario23/deep-learning-drizzle',\n",
       " 'https://github.com/src-d/awesome-machine-learning-on-source-code',\n",
       " 'https://github.com/manfreddiaz/awesome-autonomous-vehicles',\n",
       " 'https://github.com/nashory/gans-awesome-applications',\n",
       " 'https://github.com/jbhuang0604/awesome-computer-vision',\n",
       " 'https://github.com/ritchieng/the-incredible-pytorch',\n",
       " 'https://github.com/keon/awesome-nlp',\n",
       " 'https://github.com/humphd/have-fun-with-machine-learning',\n",
       " 'https://github.com/alirezadir/Production-Level-Deep-Learning',\n",
       " 'https://github.com/aikorea/awesome-rl/',\n",
       " 'https://github.com/afshinea/stanford-cs-229-machine-learning',\n",
       " 'https://github.com/terryum/awesome-deep-learning-papers',\n",
       " 'https://github.com/zotroneneis/machine_learning_basics',\n",
       " 'https://github.com/dustinvtran/ml-videos',\n",
       " 'https://github.com/JoseDeFreitas/awesome-youtubers#machine-learning',\n",
       " 'https://github.com/ujjwalkarn/Machine-Learning-Tutorials',\n",
       " 'https://github.com/ChristosChristofidis/awesome-deep-learning',\n",
       " 'https://github.com/edobashira/speech-language-processing',\n",
       " 'https://github.com/susanli2016/Machine-Learning-with-Python',\n",
       " 'https://github.com/timzhang642/3D-Machine-Learning',\n",
       " 'https://github.com/TarrySingh/Artificial-Intelligence-Deep-Learning-Machine-Learning-Tutorials',\n",
       " 'https://github.com/firmai/industry-machine-learning',\n",
       " 'https://github.com/dformoso/machine-learning-mindmap',\n",
       " 'https://github.com/tirthajyoti/Machine-Learning-with-Python',\n",
       " 'https://github.com/firmai/financial-machine-learning',\n",
       " 'https://github.com/jphall663/awesome-machine-learning-interpretability',\n",
       " 'https://github.com/krasserm/bayesian-machine-learning',\n",
       " 'https://github.com/RedditSota/state-of-the-art-result-for-machine-learning-problems',\n",
       " 'https://github.com/wtsxDev/Machine-Learning-for-Cyber-Security',\n",
       " 'https://github.com/owainlewis/awesome-artificial-intelligence',\n",
       " 'https://github.com/louisfb01/start-machine-learning',\n",
       " 'https://github.com/ashishpatel26/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code',\n",
       " 'https://github.com/fritzlabs/Awesome-Mobile-Machine-Learning',\n",
       " 'https://github.com/metrofun/machine-learning-surveys',\n",
       " 'https://github.com/eriklindernoren/ML-From-Scratch',\n",
       " 'https://github.com/HuaizhengZhang/Awesome-System-for-Machine-Learning',\n",
       " 'https://github.com/grananqvist/Awesome-Quant-Machine-Learning-Trading',\n",
       " 'https://github.com/jivoi/awesome-ml-for-cybersecurity',\n",
       " 'https://github.com/rushter/MLAlgorithms',\n",
       " 'https://github.com/huseinzol05/Stock-Prediction-Models',\n",
       " 'https://github.com/lukas/ml-class',\n",
       " 'https://github.com/huseinzol05/NLP-Models-Tensorflow',\n",
       " 'https://github.com/kjw0612/awesome-deep-vision',\n",
       " 'https://github.com/NirantK/awesome-project-ideas',\n",
       " 'https://github.com/pliang279/awesome-multimodal-ml',\n",
       " 'https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd',\n",
       " 'https://github.com/arbox/machine-learning-with-ruby',\n",
       " 'https://github.com/naganandy/graph-based-deep-learning-literature',\n",
       " 'https://github.com/weiaicunzai/awesome-image-classification',\n",
       " 'https://github.com/sbrugman/deep-learning-papers',\n",
       " 'https://github.com/abhineet123/Deep-Learning-for-Tracking-and-Detection',\n",
       " 'https://github.com/DeepGraphLearning/LiteratureDL4Graph',\n",
       " 'https://github.com/vinta/awesome-python',\n",
       " 'https://github.com/spmallick/learnopencv',\n",
       " 'https://github.com/AMAI-GmbH/AI-Expert-Roadmap',\n",
       " 'https://github.com/heartexlabs/awesome-data-labeling',\n",
       " 'https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow',\n",
       " 'https://github.com/omarsar/nlp_overview',\n",
       " 'https://github.com/mathsyouth/awesome-text-summarization',\n",
       " 'https://github.com/benedekrozemberczki/awesome-community-detection',\n",
       " 'https://github.com/D-X-Y/Awesome-AutoDL',\n",
       " 'https://github.com/shaoxiongji/knowledge-graphs',\n",
       " 'https://github.com/NiuTrans/ABigSurvey',\n",
       " 'https://github.com/fuzhenxin/Style-Transfer-in-Text',\n",
       " 'https://github.com/bharathgs/Awesome-pytorch-list',\n",
       " 'https://github.com/thunlp/TAADpapers',\n",
       " 'https://github.com/Kyubyong/nlp_tasks',\n",
       " 'https://github.com/Developer-Y/cs-video-courses#artificial-intelligence',\n",
       " 'https://github.com/openMVG/awesome_3DReconstruction_list',\n",
       " 'https://github.com/xinghaochen/awesome-hand-pose-estimation',\n",
       " 'https://github.com/balavenkatesh3322/CV-pretrained-model',\n",
       " 'https://github.com/hwalsuklee/awesome-deep-text-detection-recognition',\n",
       " 'https://github.com/lzhbrian/image-to-image-papers',\n",
       " 'https://github.com/sekwiatkowski/awesome-capsule-networks',\n",
       " 'https://github.com/unrealcv/synthetic-computer-vision',\n",
       " 'https://github.com/weihaox/awesome-neural-rendering',\n",
       " 'https://github.com/dragen1860/TensorFlow-2.x-Tutorials',\n",
       " 'https://github.com/AgaMiko/data-augmentation-review',\n",
       " 'https://github.com/MaxBenChrist/awesome_time_series_in_python',\n",
       " 'https://github.com/hoya012/awesome-anomaly-detection',\n",
       " 'https://github.com/hibayesian/awesome-automl-papers',\n",
       " 'https://github.com/cbailes/awesome-deep-trading',\n",
       " 'https://github.com/jinwchoi/awesome-action-recognition',\n",
       " 'https://github.com/amusi/awesome-object-detection',\n",
       " 'https://github.com/rasbt/pattern_classification',\n",
       " 'https://github.com/robmarkcole/satellite-image-deep-learning',\n",
       " 'https://github.com/vahidk/EffectiveTensorflow',\n",
       " 'https://github.com/Hvass-Labs/TensorFlow-Tutorials',\n",
       " 'https://github.com/zhangqianhui/AdversarialNetsPapers',\n",
       " 'https://github.com/dair-ai/nlp_paper_summaries',\n",
       " 'https://github.com/mbadry1/DeepLearning.ai-Summary',\n",
       " 'https://github.com/instillai/deep-learning-roadmap',\n",
       " 'https://github.com/onnx/models',\n",
       " 'https://github.com/jason718/awesome-self-supervised-learning',\n",
       " 'https://github.com/microsoft/nlp-recipes',\n",
       " 'https://github.com/poloclub/cnn-explainer',\n",
       " 'https://github.com/ChanChiChoi/awesome-Face_Recognition',\n",
       " 'https://github.com/aymericdamien/TopDeepLearning',\n",
       " 'https://github.com/hongleizhang/RSPapers',\n",
       " 'https://github.com/foolwood/benchmark_results',\n",
       " 'https://github.com/wzhe06/Ad-papers',\n",
       " 'https://github.com/andri27-ts/Reinforcement-Learning',\n",
       " 'https://github.com/aleju/papers',\n",
       " 'https://github.com/abhineet123/Deep-Learning-for-Tracking-and-Detection',\n",
       " 'https://github.com/GauravBh1010tt/DeepLearn',\n",
       " 'https://github.com/ageron/handson-ml',\n",
       " 'https://github.com/Avik-Jain/100-Days-Of-ML-Code',\n",
       " 'https://github.com/donnemartin/awesome-aws',\n",
       " 'https://github.com/endymecy/awesome-deeplearning-resources',\n",
       " 'https://github.com/likedan/Awesome-CoreML-Models',\n",
       " 'https://github.com/Vedenin/useful-java-links#ii-databases-search-engines-big-data-and-machine-learning',\n",
       " 'https://github.com/hindupuravinash/the-gan-zoo',\n",
       " 'https://github.com/benedekrozemberczki/awesome-decision-tree-papers',\n",
       " 'https://github.com/rwightman/pytorch-image-models',\n",
       " 'https://github.com/jslee02/awesome-robotics-libraries',\n",
       " 'https://github.com/firmai/machine-learning-asset-management',\n",
       " 'https://github.com/ahmedbahaaeldin/From-0-to-Research-Scientist-resources-guide',\n",
       " 'https://github.com/alirezadir/machine-learning-interview-enlightener/blob/main/README.md',\n",
       " 'https://github.com/DeepGraphLearning/LiteratureDL4Graph',\n",
       " 'https://github.com/ethen8181/machine-learning']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The [:-2] is to get rid of duplicate links at the very end of the list\n",
    "links = links[:-2]\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f926fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm not going to test this cell because it would take too long and might get blocked by Github\n",
    "\n",
    "# # this is the function that I used to get the top 500 most forked repos on github\n",
    "# from time import sleep\n",
    "# cards_list = []\n",
    "# link_list = []\n",
    "# for i in range(1,51):\n",
    "#     url = 'https://github.com/search?o=desc&p={}&q=stars%3A%3E1&s=forks&type=Repositories'\n",
    "#     url = url.format(i)\n",
    "#     response = requests.get(url, headers={\"user-agent\": \"Codeup\"})\n",
    "#     print(response.status_code)\n",
    "#     soup = BeautifulSoup(response.text)\n",
    "#     cards = soup.select('.repo-list-item')\n",
    "#     cards_list.append(cards)\n",
    "#     #print(i)\n",
    "#     #print(url)\n",
    "#     #print(len(cards))\n",
    "#     #print(len(cards_list))\n",
    "#     for card in cards:\n",
    "#         link = card.select_one('.v-align-middle').attrs['href']\n",
    "#         link_list.append(link)\n",
    "#     sleep(30)\n",
    "# [link[1:] for link in link_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fb832b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'link_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c2b460c78a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get an error because this relies upon the previous cell, which was not run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'link_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Get an error because this relies upon the previous cell, which was not run\n",
    "\n",
    "len(link_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8577e870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jtleek/datasharing</td>\n",
       "      <td>None</td>\n",
       "      <td>How to share data with a statistician\\n=======...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rdpeng/ProgrammingAssignment2</td>\n",
       "      <td>R</td>\n",
       "      <td>### Introduction\\n\\nThis second programming as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>octocat/Spoon-Knife</td>\n",
       "      <td>HTML</td>\n",
       "      <td>### Well hello there!\\n\\nThis repository is me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensorflow/tensorflow</td>\n",
       "      <td>C++</td>\n",
       "      <td>&lt;div align=\"center\"&gt;\\n  &lt;img src=\"https://www....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SmartThingsCommunity/SmartThingsPublic</td>\n",
       "      <td>Groovy</td>\n",
       "      <td># SmartThings Public GitHub Repo\\n\\nAn officia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     repo language  \\\n",
       "0                      jtleek/datasharing     None   \n",
       "1           rdpeng/ProgrammingAssignment2        R   \n",
       "2                     octocat/Spoon-Knife     HTML   \n",
       "3                   tensorflow/tensorflow      C++   \n",
       "4  SmartThingsCommunity/SmartThingsPublic   Groovy   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  How to share data with a statistician\\n=======...  \n",
       "1  ### Introduction\\n\\nThis second programming as...  \n",
       "2  ### Well hello there!\\n\\nThis repository is me...  \n",
       "3  <div align=\"center\">\\n  <img src=\"https://www....  \n",
       "4  # SmartThings Public GitHub Repo\\n\\nAn officia...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Skip ahead to where data was put into a cached dataframe\n",
    "\n",
    "# Create a dataframe that gives repo name, language, and readme\n",
    "df = pd.read_json('data.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09ef8392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7bcf2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How to share data with a statistician\\n===========\\n\\nThis is a guide for anyone who needs to share data with a statistician or data scientist. The target audiences I have in mind are:\\n\\n* Collaborators who need statisticians or data scientists to analyze data for them\\n* Students or postdocs in various disciplines looking for consulting advice\\n* Junior statistics students whose job it is to collate/clean/wrangle data sets\\n\\nThe goals of this guide are to provide some instruction on the best way to share data to avoid the most common pitfalls\\nand sources of delay in the transition from data collection to data analysis. The [Leek group](http://biostat.jhsph.edu/~jleek/) works with a large\\nnumber of collaborators and the number one source of variation in the speed to results is the status of the data\\nwhen they arrive at the Leek group. Based on my conversations with other statisticians this is true nearly universally.\\n\\nMy strong feeling is that statisticians should be able to handle the data in whatever state they arrive. It is important\\nto see the raw data, understand the steps in the processing pipeline, and be able to incorporate hidden sources of\\nvariability in one\\'s data analysis. On the other hand, for many data types, the processing steps are well documented\\nand standardized. So the work of converting the data from raw form to directly analyzable form can be performed \\nbefore calling on a statistician. This can dramatically speed the turnaround time, since the statistician doesn\\'t\\nhave to work through all the pre-processing steps first. \\n\\n\\nWhat you should deliver to the statistician\\n====================\\n\\nTo facilitate the most efficient and timely analysis this is the information you should pass to a statistician:\\n\\n1. The raw data.\\n2. A [tidy data set](http://vita.had.co.nz/papers/tidy-data.pdf) \\n3. A code book describing each variable and its values in the tidy data set.  \\n4. An explicit and exact recipe you used to go from 1 -> 2,3 \\n\\nLet\\'s look at each part of the data package you will transfer. \\n\\n\\n### The raw data\\n\\nIt is critical that you include the rawest form of the data that you have access to. This ensures\\nthat data provenance can be maintained throughout the workflow.  Here are some examples of the\\nraw form of data:\\n\\n* The strange [binary file](http://en.wikipedia.org/wiki/Binary_file) your measurement machine spits out\\n* The unformatted Excel file with 10 worksheets the company you contracted with sent you\\n* The complicated [JSON](http://en.wikipedia.org/wiki/JSON) data you got from scraping the [Twitter API](https://twitter.com/twitterapi)\\n* The hand-entered numbers you collected looking through a microscope\\n\\nYou know the raw data are in the right format if you: \\n\\n1. Ran no software on the data\\n1. Did not modify any of the data values\\n1. You did not remove any data from the data set\\n1. You did not summarize the data in any way\\n\\nIf you made any modifications of the raw data it is not the raw form of the data. Reporting modified data\\nas raw data is a very common way to slow down the analysis process, since the analyst will often have to do a\\nforensic study of your data to figure out why the raw data looks weird. (Also imagine what would happen if new data arrived?)\\n\\n### The tidy data set\\n\\nThe general principles of tidy data are laid out by [Hadley Wickham](http://had.co.nz/) in [this paper](http://vita.had.co.nz/papers/tidy-data.pdf)\\nand [this video](http://vimeo.com/33727555). While both the paper and the video describe tidy data using [R](http://www.r-project.org/), the principles\\nare more generally applicable:\\n\\n1. Each variable you measure should be in one column\\n1. Each different observation of that variable should be in a different row\\n1. There should be one table for each \"kind\" of variable\\n1. If you have multiple tables, they should include a column in the table that allows them to be joined or merged\\n\\nWhile these are the hard and fast rules, there are a number of other things that will make your data set much easier\\nto handle. First is to include a row at the top of each data table/spreadsheet that contains full row names. \\nSo if you measured age at diagnosis for patients, you would head that column with the name `AgeAtDiagnosis` instead\\nof something like `ADx` or another abbreviation that may be hard for another person to understand. \\n\\n\\nHere is an example of how this would work from genomics. Suppose that for 20 people you have collected gene expression measurements with \\n[RNA-sequencing](http://en.wikipedia.org/wiki/RNA-Seq). You have also collected demographic and clinical information\\nabout the patients including their age, treatment, and diagnosis. You would have one table/spreadsheet that contains the clinical/demographic\\ninformation. It would have four columns (patient id, age, treatment, diagnosis) and 21 rows (a row with variable names, then one row\\nfor every patient). You would also have one spreadsheet for the summarized genomic data. Usually this type of data\\nis summarized at the level of the number of counts per exon. Suppose you have 100,000 exons, then you would have a\\ntable/spreadsheet that had 21 rows (a row for gene names, and one row for each patient) and 100,001 columns (one row for patient\\nids and one row for each data type). \\n\\nIf you are sharing your data with the collaborator in Excel, the tidy data should be in one Excel file per table. They\\nshould not have multiple worksheets, no macros should be applied to the data, and no columns/cells should be highlighted. \\nAlternatively share the data in a [CSV](http://en.wikipedia.org/wiki/Comma-separated_values) or [TAB-delimited](http://en.wikipedia.org/wiki/Tab-separated_values) text file. (Beware however that reading CSV files into Excel can sometimes lead to non-reproducible handling of date and time variables.)\\n\\n\\n### The code book\\n\\nFor almost any data set, the measurements you calculate will need to be described in more detail than you can or should sneak\\ninto the spreadsheet. The code book contains this information. At minimum it should contain:\\n\\n1. Information about the variables (including units!) in the data set not contained in the tidy data \\n1. Information about the summary choices you made\\n1. Information about the experimental study design you used\\n\\nIn our genomics example, the analyst would want to know what the unit of measurement for each\\nclinical/demographic variable is (age in years, treatment by name/dose, level of diagnosis and how heterogeneous). They \\nwould also want to know how you picked the exons you used for summarizing the genomic data (UCSC/Ensembl, etc.). They\\nwould also want to know any other information about how you did the data collection/study design. For example,\\nare these the first 20 patients that walked into the clinic? Are they 20 highly selected patients by some characteristic\\nlike age? Are they randomized to treatments? \\n\\nA common format for this document is a Word file. There should be a section called \"Study design\" that has a thorough\\ndescription of how you collected the data. There is a section called \"Code book\" that describes each variable and its\\nunits. \\n\\n### How to code variables\\n\\nWhen you put variables into a spreadsheet there are several main categories you will run into depending on their [data type](http://en.wikipedia.org/wiki/Statistical_data_type):\\n\\n1. Continuous\\n1. Ordinal\\n1. Categorical\\n1. Missing \\n1. Censored\\n\\nContinuous variables are anything measured on a quantitative scale that could be any fractional number. An example\\nwould be something like weight measured in kg. [Ordinal data](http://en.wikipedia.org/wiki/Ordinal_data) are data that have a fixed, small (< 100) number of levels but are ordered. \\nThis could be for example survey responses where the choices are: poor, fair, good. [Categorical data](http://en.wikipedia.org/wiki/Categorical_variable) are data where there\\nare multiple categories, but they aren\\'t ordered. One example would be sex: male or female. This coding is attractive because it is self-documenting.  [Missing data](http://en.wikipedia.org/wiki/Missing_data) are data\\nthat are unobserved and you don\\'t know the mechanism. You should code missing values as `NA`. [Censored data](http://en.wikipedia.org/wiki/Censoring_\\\\(statistics\\\\)) are data\\nwhere you know the missingness mechanism on some level. Common examples are a measurement being below a detection limit\\nor a patient being lost to follow-up. They should also be coded as `NA` when you don\\'t have the data. But you should\\nalso add a new column to your tidy data called, \"VariableNameCensored\" which should have values of `TRUE` if censored \\nand `FALSE` if not. In the code book you should explain why those values are missing. It is absolutely critical to report\\nto the analyst if there is a reason you know about that some of the data are missing. You should also not [impute](http://en.wikipedia.org/wiki/Imputation_\\\\(statistics\\\\))/make up/\\nthrow away missing observations.\\n\\nIn general, try to avoid coding categorical or ordinal variables as numbers. When you enter the value for sex in the tidy\\ndata, it should be \"male\" or \"female\". The ordinal values in the data set should be \"poor\", \"fair\", and \"good\" not 1, 2 ,3.\\nThis will avoid potential mixups about which direction effects go and will help identify coding errors. \\n\\nAlways encode every piece of information about your observations using text. For example, if you are storing data in Excel and use a form of colored text or cell background formatting to indicate information about an observation (\"red variable entries were observed in experiment 1.\") then this information will not be exported (and will be lost!) when the data is exported as raw text.  Every piece of data should be encoded as actual text that can be exported.  \\n\\n### The instruction list/script\\n\\nYou may have heard this before, but [reproducibility is a big deal in computational science](http://www.sciencemag.org/content/334/6060/1226).\\nThat means, when you submit your paper, the reviewers and the rest of the world should be able to exactly replicate\\nthe analyses from raw data all the way to final results. If you are trying to be efficient, you will likely perform\\nsome summarization/data analysis steps before the data can be considered tidy. \\n\\nThe ideal thing for you to do when performing summarization is to create a computer script (in `R`, `Python`, or something else) \\nthat takes the raw data as input and produces the tidy data you are sharing as output. You can try running your script\\na couple of times and see if the code produces the same output. \\n\\nIn many cases, the person who collected the data has incentive to make it tidy for a statistician to speed the process\\nof collaboration. They may not know how to code in a scripting language. In that case, what you should provide the statistician\\nis something called [pseudocode](http://en.wikipedia.org/wiki/Pseudocode). It should look something like:\\n\\n1. Step 1 - take the raw file, run version 3.1.2 of summarize software with parameters a=1, b=2, c=3\\n1. Step 2 - run the software separately for each sample\\n1. Step 3 - take column three of outputfile.out for each sample and that is the corresponding row in the output data set\\n\\nYou should also include information about which system (Mac/Windows/Linux) you used the software on and whether you \\ntried it more than once to confirm it gave the same results. Ideally, you will run this by a fellow student/labmate\\nto confirm that they can obtain the same output file you did. \\n\\n\\n\\n\\nWhat you should expect from the analyst\\n====================\\n\\nWhen you turn over a properly tidied data set it dramatically decreases the workload on the statistician. So hopefully\\nthey will get back to you much sooner. But most careful statisticians will check your recipe, ask questions about\\nsteps you performed, and try to confirm that they can obtain the same tidy data that you did with, at minimum, spot\\nchecks.\\n\\nYou should then expect from the statistician:\\n\\n1. An analysis script that performs each of the analyses (not just instructions)\\n1. The exact computer code they used to run the analysis\\n1. All output files/figures they generated. \\n\\nThis is the information you will use in the supplement to establish reproducibility and precision of your results. Each\\nof the steps in the analysis should be clearly explained and you should ask questions when you don\\'t understand\\nwhat the analyst did. It is the responsibility of both the statistician and the scientist to understand the statistical\\nanalysis. You may not be able to perform the exact analyses without the statistician\\'s code, but you should be able\\nto explain why the statistician performed each step to a labmate/your principal investigator. \\n\\n\\nContributors\\n====================\\n\\n* [Jeff Leek](http://biostat.jhsph.edu/~jleek/) - Wrote the initial version.\\n* [L. Collado-Torres](http://bit.ly/LColladoTorres) - Fixed typos, added links.\\n* [Nick Reich](http://people.umass.edu/nick/) - Added tips on storing data as text.\\n* [Nick Horton](https://www.amherst.edu/people/facstaff/nhorton) - Minor wording suggestions.\\n\\n\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This pulls the row with 0 index, and the column \"readme_contents\"\n",
    "df.loc[0 ,'readme_contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20f2fa31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JavaScript          100\n",
       "Java                 77\n",
       "NaN                  60\n",
       "Python               54\n",
       "C++                  30\n",
       "TypeScript           26\n",
       "Jupyter Notebook     26\n",
       "Go                   19\n",
       "HTML                 16\n",
       "C                    15\n",
       "PHP                  12\n",
       "Ruby                 11\n",
       "Shell                 8\n",
       "Kotlin                5\n",
       "CSS                   5\n",
       "C#                    4\n",
       "Swift                 4\n",
       "Rascal                3\n",
       "Vue                   3\n",
       "Scala                 2\n",
       "Objective-C           2\n",
       "Nix                   2\n",
       "Dart                  2\n",
       "R                     2\n",
       "Assembly              1\n",
       "ApacheConf            1\n",
       "SCSS                  1\n",
       "Dockerfile            1\n",
       "TeX                   1\n",
       "PowerShell            1\n",
       "Vim script            1\n",
       "Rich Text Format      1\n",
       "Nunjucks              1\n",
       "Groovy                1\n",
       "Less                  1\n",
       "Rust                  1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.language.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60a01843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo                0\n",
       "language           60\n",
       "readme_contents     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There a bunch of nulls for language, but not for the other features\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "16bc61e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a list of the top 4 repo names\n",
    "top4 = ['JavaScript', 'Java', 'Python', 'C++']\n",
    "\n",
    "# This places all repos not in the top 4 into the 'other' catagory\n",
    "df.language = df.language.apply(lambda x: 'Other' if x not in top4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "40d92451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Other         239\n",
       "JavaScript    100\n",
       "Java           77\n",
       "Python         54\n",
       "C++            30\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "031b60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows where language put into 'other' category\n",
    "\n",
    "df = df[df.language != 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a3ed104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Proportion: 0.60 (156 rows)\n",
      "Validate Proportion: 0.20 (52 rows)    \n",
      "Test Proportion: 0.20 (53 rows)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((156, 3), (52, 3), (53, 3))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "\n",
    "train, validate, text = p.split_readme(df)\n",
    "\n",
    "train.shape, validate.shape, text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1983e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_counts_and_ratios(df, column):\n",
    "    labels = pd.concat([df[column].value_counts(),\n",
    "                       df[column].value_counts(normalize=True)], axis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
